{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(5)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([2 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor([4], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.batch(2)\n",
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor([8], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda z : z*2)\n",
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.unbatch()\n",
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x : x > 3) # keep only > 3\n",
    "for item in dataset.take(2) : # get 2 sample\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 4 2 3 5 0], shape=(6,), dtype=int64)\n",
      "tf.Tensor([ 6  9  8 12 10 13], shape=(6,), dtype=int64)\n",
      "tf.Tensor([11 14 15  7 19 16], shape=(6,), dtype=int64)\n",
      "tf.Tensor([17 18], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(20)\n",
    "dataset = dataset.shuffle(buffer_size=4, seed=42).batch(6)\n",
    "for item in dataset :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the Data to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For a very large dataset that does not fit in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, name_prefix, header=None, n_parts=5) :\n",
    "    data_dir = os.path.join('dataset', 'housing')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    path_format = os.path.join(data_dir, '_{}_{:02d}.csv')\n",
    "\n",
    "    filepath = []\n",
    "    m = len(data)\n",
    "    for file_id, row_ in enumerate(np.array_split(np.arange(m), n_parts)) : # like batch\n",
    "        part_csv = path_format.format(name_prefix, file_id)\n",
    "        filepath.append(part_csv)\n",
    "\n",
    "        with open(part_csv, 'wt', encoding='utf-8') as file : # write text mode\n",
    "            if header : \n",
    "                file.write(header)\n",
    "                file.write('\\n')\n",
    "            for row_id in row_ :\n",
    "                file.write(','.join([ repr(column) for column in data[row_id] ]))\n",
    "                file.write('\\n')\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map x and y\n",
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + ['MedianHouseValue'] # x and y\n",
    "header = ','.join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_csv(train_data, \"train\", header, n_parts=5)\n",
    "valid_filepaths = save_to_csv(valid_data, \"valid\", header, n_parts=3)\n",
    "test_filepaths = save_to_csv(test_data, \"test\", header, n_parts=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's take a peek at the first few lines of one of these CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5214</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.049945</td>\n",
       "      <td>1.106548</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.490060</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>3.443340</td>\n",
       "      <td>33.69</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.542373</td>\n",
       "      <td>1.591525</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2.250847</td>\n",
       "      <td>38.44</td>\n",
       "      <td>-122.98</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1736</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.289003</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-117.70</td>\n",
       "      <td>2.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.312457</td>\n",
       "      <td>1.085092</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2.244384</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-116.93</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
       "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
       "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
       "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
       "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -122.43             1.442  \n",
       "1    -117.39             1.687  \n",
       "2    -122.98             1.621  \n",
       "3    -117.70             2.621  \n",
       "4    -116.93             0.956  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'dataset\\\\housing\\\\_train_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'dataset\\\\housing\\\\_train_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'dataset\\\\housing\\\\_train_01.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'dataset\\\\housing\\\\_train_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'dataset\\\\housing\\\\_train_02.csv', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42) # shuffle  \n",
    "for filepath in filepath_dataset :\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reader = 2\n",
    "dataset = filepath_dataset.interleave( # like pipeline\n",
    "    lambda filepath : tf.data.TextLineDataset(filepath).skip(1), # skip line 1\n",
    "    cycle_length = n_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4.163,49.0,4.71830985915493,0.9894366197183099,660.0,2.323943661971831,37.54,-122.31,3.938'\n",
      "b'2.0134,23.0,4.046153846153846,1.1692307692307693,245.0,1.8846153846153846,38.3,-122.28,1.425'\n",
      "b'4.5293,19.0,6.920661157024793,1.1305785123966943,1827.0,3.0198347107438015,38.34,-122.31,2.104'\n",
      "b'2.3319,15.0,5.488745980707395,1.0707395498392283,2097.0,3.3713826366559485,32.68,-115.48,0.912'\n",
      "b'4.2708,45.0,5.121387283236994,0.953757225433526,492.0,2.8439306358381504,37.48,-122.19,2.67'\n",
      "b'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73,-118.31,3.215'\n",
      "b'4.7426,19.0,5.871428571428571,1.022857142857143,1064.0,3.04,37.93,-121.66,2.631'\n",
      "b'4.4474,25.0,6.342776203966006,1.0226628895184136,928.0,2.6288951841359776,38.03,-122.26,2.037'\n",
      "b'2.3912,34.0,5.652960526315789,1.144736842105263,1783.0,2.932565789473684,35.16,-119.45,0.529'\n",
      "b'2.6591,24.0,5.244299674267101,1.0,748.0,2.436482084690554,40.57,-122.34,0.828'\n"
     ]
    }
   ],
   "source": [
    "for line in dataset.take(10) : # take 10 lines \n",
    "    print(line.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63e79917a05e390872358bfb73c58bc903ada01d2d04077091749088207d82cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
